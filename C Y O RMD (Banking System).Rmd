---
title: "Interlinkages in the Malaysian Banking System"
author: "Pulapa Sai Prasanth"
date: "11/04/2021"
output:
  pdf_document: default
  word_document: default
subtitle: Principal Component Analysis on Sector-Wide Macrofinancial Indicators
abstract: This report documents a principal component analysis exercise to identify
  a cluster of indicators with potential predictive power to forecast deterioration
  in a Malaysia banking system's portfolio or costs, developed to detect potential
  warning signs in the wider banking system.
keywords: principal component analysis, macrofinancial indicators, regularised iterative
  PCA algorithm, missing value
---

```{r, eval=TRUE, echo=FALSE, warning=FALSE, message=FALSE, fig.keep='none'}
library(missMDA)
library(FactoMineR)
library(ggfortify)
library(cluster)
library(knitr)
library(ggplot2)
library(ggthemes)
library(RColorBrewer)
library(readxl)
# To use own downloaded dataset from http://www.bnm.gov.my/index.php?ch=statistic
indicators.raw <- read_excel("/Users/saipr/Documents/EWS PCA.xlsx", sheet = "Transformed Indicators")
indicators <- data.frame(indicators.raw)

indicators.raw$MonthYr <- format(as.Date(indicators.raw$Month), "%Y-%m")  # To obtain year-month format
indicators.raw$Month <- as.Date(indicators.raw$Month)  # Converting "Month" from character class to date class

raw.summary.stats <- data.frame(Minimum = apply(na.omit(indicators.raw[, c(2:10, 12:15)]), 2, min),
                                Maximum = apply(na.omit(indicators.raw[, c(2:10, 12:15)]), 2, max),
                                Mean = apply(na.omit(indicators.raw[, c(2:10, 12:15)]), 2, mean),
                                Median = apply(na.omit(indicators.raw[, c(2:10, 12:15)]), 2, median),
                                StDev = apply(na.omit(indicators.raw[, c(2:10, 12:15)]), 2, sd),
                                Count = apply(na.omit(indicators.raw[, c(2:10, 12:15)]), 2, length))

# Imputing missing values using regularised iterative PCA algorithm
indicators.imputed.adj <- imputePCA(indicators[-21, c(2:10, 12:15)],
                                    ncp = 5, scale = TRUE,
                                    method = "Regularized")

# Imputing missing values for dataset including npl.r
indicators.imputed.nplr <- imputePCA(indicators[-21, 2:15],
                                    ncp = 10, scale = TRUE,
                                    method = "Regularized")

pca.ews <- PCA(indicators.imputed.adj$completeObs)

# In-built R PCA proceduree
pca.ews.R <- prcomp(indicators.imputed.adj$completeObs, scale. = TRUE)
# ews.pca.adj$sdev^2  # Eigenvalues row vector

indicators.pca.ews <- data.frame(cbind(indicators.imputed.adj$completeObs, pca.ews.R$x[, 1:3]))
indicators.pca.ews.econyy <- data.frame(cbind(indicators.pca.ews, indicators.imputed.nplr$completeObs[, 10], indicators$econ.yy[-21]))
colnames(indicators.pca.ews.econyy)[17] = "npl.r"
colnames(indicators.pca.ews.econyy)[18] = "econ.yy"

# Summary statistics (to compare with line 21)
imputed.summary.stats <- data.frame(Minimum = apply(indicators.pca.ews[, 1:13], 2, min),
                                    Maximum = apply(indicators.pca.ews[, 1:13], 2, max),
                                    Mean = apply(indicators.pca.ews[, 1:13], 2, mean),
                                    Median = apply(indicators.pca.ews[, 1:13], 2, median),
                                    StDev = apply(indicators.pca.ews[, 1:13], 2, sd), 
                                    Count = apply(indicators.pca.ews[, 1:13], 2, length))
```

# Introduction, Motivation and Data

This exercise is done based on the need to identify latent factors that will be used to forecast deterioration in Malaysia banking system's portfolio or costs, using measurements such as:

- The banking system's nonperforming loans (NPL) ratio;
- The banking system's cost of funds, relative to rates such as the Kuala Lumpur Interbank Offered Rate (KLIBOR) or Bank Negara Malaysia's (BNM's) Overnight Policy Rate (OPR);
- The banking systems's credit default swap (CDS) spreads, in terms of both absolute and relative to the sovereign CDS or an asset-weighted average of the CDS spread of competitor banks.

In this exercise, a principal component analysis (PCA) is done on economy-wide macrofinancial indicators to identify potential sector-wide linkages between these variables. The dataset used in this execise was sourced from BNM, which can be sourced from http://www.bnm.gov.my/index.php?ch=statistic and transformed to produce the following variables:

* Ratios to total deposits:
    + Demand deposits ratio (`dd.deposits.r`)
    + Foreign currency deposits ratio (`fx.deposits.r`)
    + Repurchase agreements ratio (`repo.deposits.r`)
* Ratios to total loan applied:
    + Passenger car loan application ratio (`loan.app.cars.r`)
    + Construction loan application ratio (`loan.app.construction.r`)
    + Non-residential property loan application ratio (`loan.app.nonresprop.r`)
    + Residential property loan application ratio (`loan.app.resprop.r`)
    + Working capital loan application ratio (`loan.app.workingcapital.r`)
* Total loans applied growth rate (`loan.yy`)
* Liquidity capital ratio (`lcr`)

PCA is useful in this endeavour as it involves reducing data dimensionality to provide a subspace that best represents the data in the sense of maximising the variability of the projected points.

# Analysis Part I: Imputing Missing Values in the Dataset

In order to proceed with PCA, the dataset would first need to be "balanced" - i.e. there needs to be an equal amount of entries for each of the variable in the dataset. Dataset used here is inherently "unbalanced" due to the different starting points to which the data was first reported. As a result, there are clusters of variables with different number of observations; `npl.r`, which has data as far back as January 1997, has 270 observations, whereas `lcr`, which BNM only began reporting in June 2015, only has 40 recorded observations. If PCA is done on this raw dataset, the size of dataset included in the analysis will be constrained to the size of the variable with the least amount of entries and the entries which all variables concurrently recorded an observation. To illustrate this, the following is a graph of the available NPL ratio data (which BNM only began reporting in December 2008), which has recorded observations less than half of the variable with the longest reporting time frame in the dataset:

```{r, eval=TRUE, tidy=TRUE, echo=FALSE, warning=FALSE, message=FALSE, fig.keep='all', fig.align='center', fig.height=4, fig.cap="NPL ratio, as reported by BNM"}
ggplot(indicators.raw, aes(Month, npl.r)) +
  scale_x_date(date_labels = "%b-%Y") +
  geom_line(color = "darkred") +
  geom_point() +
  xlab("Date") +
  ylab("NPL Ratio") +
  scale_x_date(breaks = "24 months", date_labels = "%b %y") +
  theme_light()
```

To overcome this problem, a method formulated in [Josse and Husson (2012)](http://revues-sfds.math.cnrs.fr/index.php/J-SFdS/article/view/122/112) provided an algorithm, called the regularised iterative PCA algorithm, to impute the missing values using existing principal axes and components in the dataset whilst simultaneously overcoming the issue of overfitting. The R Package `missMDA` developed in [Josse and Husson (2016)](https://www.jstatsoft.org/article/view/v070i01) is used to perform principal component methods on incomplete data, aiming at estimating parameters and obtaining graphical representations despite mising values. Using these algorithms yields the following graph of imputed NPL ratio for entries before December 2008 and maintaining the original values December 2008 onwards:

\newpage

```{r, eval=TRUE, tidy=TRUE, echo=FALSE, warning=FALSE, message=FALSE, fig.keep='all', fig.align='center', fig.height=4, fig.cap="NPL ratio with imputed values for observations before December 2008"}
ggplot(indicators.pca.ews.econyy, aes(indicators.raw$Month[-21], npl.r)) +
  scale_x_date(date_labels = "%b-%Y") +
  geom_line(color = "darkred") +
  geom_point() +
  xlab("Date") +
  ylab("NPL Ratio") +
  scale_x_date(breaks = "24 months", date_labels = "%b %y") +
  theme_light()
```

Note that in Figure 2, the algorithm imputed high NPL ratios in mid-1997 -- reflecting onset of the Asian Financial Crisis -- without explicit specification in the model. The imputed values does, however, affect the inter-variable relationships, by either strengthening existing correlations in the original dataset (see Figures 3 and 4). The full summary statistics of the datasets before and after the transformation are tabled in the Appendix section.

```{r, eval=TRUE, tidy=TRUE, echo=FALSE, warning=FALSE, message=FALSE, fig.keep='all', fig.align='center', fig.cap="Relationship between loan application ratios in the raw dataset"}
pairs(na.omit(indicators.raw[, 5:10]), panel = panel.smooth)
```

```{r, eval=TRUE, tidy=TRUE, echo=FALSE, warning=FALSE, message=FALSE, fig.keep='all', fig.align='center', fig.cap="Relationship between loan application ratios in the imputed dataset"}
pairs(indicators.pca.ews.econyy[, 4:9], panel = panel.smooth)
```

\newpage

# Analysis Part II: Running the PCA

## **How many principal components (PCs) to retain? Eigendecomposition -- computing eigenvalues**

The core idea behind PCA is to reduce the dimensionality, i.e. reduce the number of variables, of a dataset while retaining as much as possible of the variation present in the data. When running the PCA on the new transformed dataset with imputed and original values, the analysis yields eigenvalues, i.e. a vector of values that provide information about the amount of variability captured by each principal component (PC). Each eigenvalue covers a proportion of variation that exists in the dataset. The following shows a table and screeplot (Figure 5) of eigenvalues of each PC (listed as "comp") from the PCA:

```{r, eval=TRUE, tidy=TRUE, echo=FALSE, warning=FALSE}
kable(round(pca.ews$eig, digits = 3), caption = "Table of eigenvalues")
```

```{r, eval=TRUE, tidy=TRUE, echo=FALSE, warning=FALSE, fig.keep='all', fig.align='center', fig.height=4, fig.cap="Screeplot of eigenvalues"}
barplot(pca.ews$eig[, "eigenvalue"],
        border = TRUE, col = "darkred", ylim = c(0, 5), las = 2,
        ylab = "Eigenvalue",
        names.arg = rownames(pca.ews$eig))
```

Since the exercise is to determine the number of dimensions to reduce, the amount of variance each PC covers is a useful metric to decide which PCs to retain. There is no universal criterion to determine the number of PCs to retain. From Table 1, the percentage of variance captured by the first two dimensions covers over half (57.6%) of the entire variation in the dataset. The percentage variance captured by the first three dimensions covers roughly two-thirds of the entire variation in the dataset (67.2%). In this exercise, the first two PCs will be given the most focus, while the third PC is included intermittently for comparative and illustrative purposes.

\newpage

## **Which variables characterise each PCs?**

To see how each PC is characterised, the correlations between the variables and the PCs (listed in the Table 4 as "Dim") are evaluated:

```{r, eval=TRUE, tidy=TRUE, echo=FALSE, warning=FALSE}
kable(round(pca.ews$var$coord[, 1:2], digits = 3), caption = "Correlations between variables and PCs")
```

Taking residential property loan applications ratio (`loan.app.resprop.r`) as an example, notice that PC1 has a strong positive correlation with `loan.app.resprop.r` whilst registering an insignificant, negative correlation with PC2. These statistics can be plotted as a radar or circle of correlations (see Figure 6). The closer an arrow is to the circumference of the circle, the better its representation on the given axes. Also note how the variables are grouped.

```{r, eval=TRUE, tidy=TRUE, echo=FALSE, warning=FALSE, fig.keep='all', fig.align='center', fig.height=4, fig.cap="Variables factor map"}
plot(pca.ews, choix = "var")
```

\newpage

## **Influence of variables in each PC**

Another perspective to evaluate how variables characterise each PCs is to examine the contributions of each variable to each PCs. The following table lists the proportion of each variable that make up a single PC (listed in Table 5 as "Dim"):

```{r, eval=TRUE, tidy=TRUE, echo=FALSE, warning=FALSE}
kable(round(rbind(pca.ews$var$contrib, TOTAL = colSums(pca.ews$var$contrib)), digit = 3), caption = "Contributions of variables on each PC")
```

\newpage

# Results

## **Plotting PC scores**

From the PCA exercise, the PC scores derived from each observation can be used as coordinates to plot the objects in a scatterplot. In Figure 7, each PC score is also applied a colour gradient to visualise the impact of moving towards certain regions in the PC1-PC2 plot on NPL ratios. Here we can observe that moving into the negative region of PC1 generally implies higher NPL ratios. This gives a the PC1 axis a strong predictive power on the general outlook of banks' loan portfolio performance.

```{r, eval=TRUE, tidy=TRUE, echo=FALSE, warning=FALSE, fig.keep='all', fig.align='center', fig.cap="Scatterplot of PC scores on first two PC axes, applied colour gradient to each point to scale NPL ratio"}
ggplot(indicators.pca.ews.econyy, aes(PC1, PC2, PC3, color = npl.r)) +
  geom_hline(yintercept = 0, color = "gray70") +
  geom_vline(xintercept = 0, color = "gray70") +
  geom_point() +
  scale_colour_gradient(low = "rosybrown1", high = "darkred") +
  labs(title = "Early Warning System PCA plot of observations", subtitle = "with percentage of variance in parentheses") +
  xlab("PC1 (31.03%)") +  # Labelled with the correspnding percentage of variance for PC1
  ylab("PC2 (26.54%)") +  # Labelled with the correspnding percentage of variance for PC2
  labs(color = "NPL Ratio", size = "NPL Ratio") +
  theme_light()
```

\newpage

# Conclusion

In this paper, I have carried out a regularised imputed PCA algorithm to impute missing values in historical datasets and used the new transformed and uniform dataset for a second order PCA to extract the factors and sensitivities that drives the performance of the Malaysian banking system stemming from the performance of various macrofinancial indicators. This exercise shows how extremely complex, dynamic and interlinked the banking sector and how small gyrations in this sector can potentially impact the wider economy and vice versa. With this exercise, we can have a better understanding on how a cluster of factors can contribute to the overall macro effect, not simply through their individual mechanical effects, but also through their aggregated micro effects on each other.

\newpage

# Appendix

The regularised iterative PCA algorithm transforms the original workable dataset from the Table 4 to Table 5 (note the number of observations for each variable under the column "Count"):

```{r, eval=TRUE, tidy=TRUE, echo=FALSE, warning=FALSE}
kable(round(raw.summary.stats, digits = 3), caption = "Before transformation")
kable(round(imputed.summary.stats, digits = 3), caption = "After transformation")
```

Focusing on the first three PCs, the contribution for each variable are plotted in the following figures:

```{r, eval=TRUE, tidy=TRUE, echo=FALSE, warning=FALSE, fig.keep='all', fig.align='center', fig.cap="Influence of each macrofinancial indicators on PC1"}
ggplot(as.data.frame(pca.ews$var$contrib), aes(x = row.names(as.data.frame(pca.ews$var$contrib)), y = Dim.1)) +
  geom_bar(position = "dodge", stat = "identity", fill = "darkred") +
  geom_text(aes(label = round(pca.ews$var$contrib[, 1], digits = 2), vjust = -0.3)) +
  labs(subtitle = "Note: Overall percentage of variance captured by PC1 is 31.03%") +
  xlab("Macrofinancial Indicators") +
  ylab("% contribution to PC1") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
        panel.background = element_rect(fill = "white", colour = "gray70"),
        panel.grid.major = element_line(colour = "gray90", size = rel(0.5)),
        panel.grid.minor = element_line(colour = "gray90", size = rel(0.25)))
```

```{r, eval=TRUE, tidy=TRUE, echo=FALSE, warning=FALSE, fig.keep='all', fig.align='center', fig.cap="Influence of each macrofinancial indicators on PC2"}
ggplot(as.data.frame(pca.ews$var$contrib), aes(x = row.names(as.data.frame(pca.ews$var$contrib)), y = Dim.2)) +
  geom_bar(position = "dodge", stat = "identity", fill = "darkred") +
  geom_text(aes(label = round(pca.ews$var$contrib[, 2], digits = 2), vjust = -0.3)) +
  labs(subtitle = "Note: Overall percentage of variance captured by PC2 is 26.54%") +
  xlab("Macrofinancial Indicators") +
  ylab("% contribution to PC2") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
        panel.background = element_rect(fill = "white", colour = "gray70"),
        panel.grid.major = element_line(colour = "gray90", size = rel(0.5)),
        panel.grid.minor = element_line(colour = "gray90", size = rel(0.25)))
```

```{r, eval=TRUE, tidy=TRUE, echo=FALSE, warning=FALSE, fig.keep='all', fig.align='center', fig.cap="Influence of each macrofinancial indicators on PC3"}
ggplot(as.data.frame(pca.ews$var$contrib), aes(x = row.names(as.data.frame(pca.ews$var$contrib)), y = Dim.3)) +
  geom_bar(position = "dodge", stat = "identity", fill = "darkred") +
  geom_text(aes(label = round(pca.ews$var$contrib[, 3], digits = 2), vjust = -0.3)) +
  labs(subtitle = "Note: Overall percentage of variance captured by PC3 is 9.66%") +
  xlab("Macrofinancial Indicators") +
  ylab("% contribution to PC3") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
        panel.background = element_rect(fill = "white", colour = "gray70"),
        panel.grid.major = element_line(colour = "gray90", size = rel(0.5)),
        panel.grid.minor = element_line(colour = "gray90", size = rel(0.25)))
```

